# -*- coding: utf-8 -*-
"""sih_ps_scrapper

Automatically generated by Colaboratory.

"""

from bs4 import BeautifulSoup as bs4
import pandas as pd

url = "https://www.sih.gov.in/sih2020PS/MTA=/U29mdHdhcmU=/QWxs/QWxs?page={}"

import requests
table_data = pd.DataFrame()
from tqdm import tqdm
for i in tqdm(range(1,5)):
    html = requests.get(url.format(i)).text
    soup = bs4(html,"html.parser")
    table = soup.find("table")
    data = pd.read_html(table.prettify())
    if len(data)==1:
        break
    data = data[0]
    data.columns = [i[0].strip()  for i in data.columns]
    descriptions = list(data[data.Logo == "Description"]['Organization'])
    Youtube_link = list(data[data.Logo == "Youtube Link"]['Organization'])
    Dataset_Link = list(data[data.Logo == "Dataset Link"]['Organization'])
    data = data[data.Logo == 'Ã—']
    data['Description'] = descriptions
    data['youtube_Link'] = Youtube_link
    data['Dataset_Link'] = Dataset_Link
    table_data = pd.concat([table_data,data])

table_data.shape

df = pd.DataFrame(table_data,columns=['Logo', 'Organization', 'Problem Statement Title','Description',
       'PS Number', 'Domain Bucket', 'Category', 'Youtube Link',
       'Dataset Link'])

df.to_excel(r'app_dev.xlsx')